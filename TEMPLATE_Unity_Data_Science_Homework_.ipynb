{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndcLQ_YjDsx-"
      },
      "source": [
        "# ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️\n",
        "# MAKE A COPY OF THIS NOTEBOOK ON YOUR OWN GDRIVE\n",
        "# Changes to this notebook will not be saved.\n",
        "# ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eg423sT0X8N"
      },
      "source": [
        "# Unity Data Science Homework - Specification\n",
        "\n",
        "At Unity, we develop **deep learning models** for [Real-Time Bidding (RTB)](https://en.wikipedia.org/wiki/Real-time_bidding).\n",
        "\n",
        "To bid for an ad impression, we estimate the optimal bid value using the predicted install probability together with several other predictions.\n",
        "\n",
        "In this homework, your task is to train a **Deep Learning Model** using the data sampled from our production environment and to ​predict the install probabilities for the ad impressions included in the test data.\n",
        "\n",
        "Note that the install probability predicted by your model will be used directly for estimating the optimal bid values of ad impressions. Therefore, it is important for the predictions to be as accurate as possible.\n",
        "\n",
        "**Here are the guidelines for the homework:**\n",
        "*   Complete the homework using python and any libraries of your choice (for example, numpy, scikit learn, Tensorflow, PyTorch, etc.)\n",
        "*   You're free to use any type of model for your imemdiate steps, but your final model **must** be a Neural Network\n",
        "*   Use ​**ROC AUC, log loss**,​ and **​prediction bias**​ to evaluate model performance. Feel free to use **other metrics** to discuss a model’s merit\n",
        "*   Perform exploratory data analysis.\n",
        "*   Keep code clean and organized.\n",
        "*   Please include all of your intermediate models and results (even if they don't work, it will help us understand your model development)\n",
        "*   Structure your work to showcase your understanding of the important steps leading to your final solution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1AdPZrBOkjh"
      },
      "source": [
        "# Colab setup\n",
        "\n",
        "The default kernel of this notebook is set to CPU. You can use a GPU kernel when working on parts of your solution that requires more compute. Note that you will have a daily limit on the usage of those kernels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEiMgV8w-Vsg"
      },
      "source": [
        "## Download Data\n",
        "\n",
        "Run the next cell to download the two datasets required for this homework. You will need to authenticate using your google account to be able to download the files. (This will take about 1.5 minutes to download)\n",
        "\n",
        "The two files are `train_data.csv` and `assessment_data.csv` (saved into the variables `TRAIN_DATA_PATH` and `ASSESSMENT_DATA_PATH` respectively)\n",
        "\n",
        "`train_data.csv` has install labels. `assessment_data.csv` does not. The `assessment_data.csv` is used for assessing your submission.\n",
        "\n",
        "They can be loaded with pandas like so:\n",
        "```\n",
        "import pandas as pd\n",
        "trainDF = pd.read_csv(TRAIN_DATA_PATH, delimiter=';')\n",
        "assessmentDF = pd.read_csv(ASSESSMENT_DATA_PATH, delimiter=';')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERwFYyWW5joT"
      },
      "source": [
        "!pip install PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "TRAIN_DATA_PATH = 'train_data.csv'\n",
        "ASSESSMENT_DATA_PATH = 'assessment_data.csv'\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1N3n7ThL-4mRod-lwgy047LkFeZ5iGFuJ\"})\n",
        "downloaded.GetContentFile(TRAIN_DATA_PATH)\n",
        "print(f'Downloaded: {TRAIN_DATA_PATH}')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1BCQuIIE-Kh61ExDuhWNLOPae-9Q3m6IL\"})\n",
        "downloaded.GetContentFile(ASSESSMENT_DATA_PATH)\n",
        "print(f'Downloaded: {ASSESSMENT_DATA_PATH}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFOd1rxf-6oe"
      },
      "source": [
        "## Deliverables\n",
        "\n",
        "- This Jupyter notebook containing:\n",
        "    - All code to produce the results\n",
        "    - Exploratory data analysis\n",
        "    - Modelling approach\n",
        "    - Performance evaluation of the model\n",
        "    - Explanation of design choices\n",
        "    - Discussion of future work\n",
        "- A CSV file that contains the predicted install probabilities of ad impressions in the `assessment_data.csv`. The file should have the following columns only:\n",
        "    - ```id```: ID of ad impression in the test data\n",
        "    - ```install_proba```: Predicted install probability of ad impression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuSnGy735Vik"
      },
      "source": [
        "## Data description\n",
        "\n",
        "- ```id```: impression id\n",
        "- ```timestamp```: time of the event in UTC\n",
        "- ```campaignId```: id of the advertising campaign (the game being advertised)\n",
        "- ```platform```: device platform\n",
        "- ```softwareVersion```: OS version of the device\n",
        "- ```sourceGameId```: id of the publishing game (the game being played)\n",
        "- ```country```: country of user\n",
        "- ```startCount```: how many times the user has started (any) campaigns\n",
        "- ```viewCount```: how many times the user has viewed (any) campaigns\n",
        "- ```clickCount```: how many times the user has clicked (any) campaigns\n",
        "- ```installCount```: how many times the user has installed games from this ad network\n",
        "- ```lastStart```: last time user started any campaign\n",
        "- ```startCount1d```: how many times user has started (any) campaigns within the last 24 hours\n",
        "- ```startCount7d```: how many times user has started (any) campaigns within the last 7 days\n",
        "- ```connectionType```: internet connection type\n",
        "- ```deviceType```: device model\n",
        "- ```install```: binary indicator if an install was observed (install=1) or not (install=0) after impression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7th-NhFBZZC"
      },
      "source": [
        "# Your submission:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOWS0_snB33E"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}